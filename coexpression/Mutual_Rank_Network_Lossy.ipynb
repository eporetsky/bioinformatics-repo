{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "czech-pixel",
   "metadata": {},
   "source": [
    "# Generating Mutual Rank correlation networks (lossy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-capability",
   "metadata": {},
   "source": [
    "This notebook produces Mutual Rank networks where some of the original correlation information is lost.\\\n",
    "In order reduce the size of the all-vs-all correlation table (often 40k x 40k table), the results are\\\n",
    "rounded and converted to int8 and then saved in a compressed datatable JAY format. Because int8 can store\\\n",
    "up to 256 unique integers, all MR values above 250 are discarded (although they are rarely used anyway).\\\n",
    "The improved compression had only minor effects on the final observed networks but it reduced the size\\\n",
    "of the MR correlation file from >20gb to about 2gb, which was helpful when working with multiple gene\\\n",
    "expression datasets.\\\n",
    "\\\n",
    "The code in this notebook can run a full analysis of an MR correlation network as described in (Wisecaver, 2017)\\\n",
    "10.1105/tpc.17.00009. It does require enough RAM to load 2 ranked all-vs-all correlation tables at the same time\\\n",
    "and a workstation with ~96gb RAM is recommended for large datasets. It is fairly fast, taking about 1-2 hours per\\\n",
    "dataset, but I have not benchedmarked it against other methods.\\\n",
    "\\\n",
    "This code has only been tested on linux and might be hard to get to work in other environments.\\\n",
    "For now you need to install **csvformat**: sudo apt install csvkit\\\n",
    "(I think datatable added an option to save as tsv so might not need csvkit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import datatable as dt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from nancorrmp.nancorrmp import NaNCorrMp\n",
    "from multiprocessing import  Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-sharing",
   "metadata": {},
   "source": [
    "# Functions for generating the MR correlation networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-refrigerator",
   "metadata": {},
   "source": [
    "### Main MR network function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mr_network(name, e_val):\n",
    "    global dfone # needs to be gloval for the parallel function in the end\n",
    "    # Convert the MR matrix to an exponential decay matrix\n",
    "    corr = dt.fread(\"mrs/\"+name+\".mrs.jay\").to_pandas().astype(\"int16\") \n",
    "    corr.index = corr.columns\n",
    "    corr = corr + 125\n",
    "    corr = corr.mask(corr == 0, 251) # This value won't be included in network\n",
    "\n",
    "    print(\"3. Converting MR matrix using exponential decay (ED) value of: \"+str(e_val))\n",
    "    corr = np.exp(-(corr-1.0)/e_val)\n",
    "    corr = corr.mask(corr < 0.01, 0)\n",
    "    corr = corr.loc[(corr.sum(axis=1) != 1), (corr.sum(axis=0) != 1)]\n",
    "    #print(\"Second:\", corr.iloc[:5,:5])\n",
    "    print(\"4. Processing ED matrix in order produce an edge list file\")\n",
    "    # Changes lower triangle and diagonal to NaN\n",
    "    corr = corr.mask(np.arange(len(corr))[:,None] >= np.arange(len(corr)))\n",
    "    # Make sure file doesn't exist because data appends to it\n",
    "    if os.path.exists(\"temp_edge_list.csv\"): os.remove(\"temp_edge_list.csv\")\n",
    "    #print(\"Third:\", corr.iloc[:5,:5])\n",
    "    # ClusterONE doesn't work with header\n",
    "    range_indices = [[start, start+1000] for start in range(0, len(corr), 1000)]\n",
    "    range_indices[-1][-1] = len(corr)\n",
    "    for ind in range_indices:\n",
    "        a = corr.iloc[ind[0]:ind[1]].copy()\n",
    "        a = a.unstack().reset_index()\n",
    "        a = a[(a[0]>0) & ( ~ np.isnan(a[0]) )] # & (a[0]<1)]\n",
    "        dt.Frame(a).to_csv(\"temp_edge_list.csv\", append=True, header=False)\n",
    "    # Since ClusterONE uses only tsv format for the edge list, and dt only saves csv need to convert\n",
    "    os.system(\"csvformat -T temp_edge_list.csv > temp_edge_list.tsv\")\n",
    "    #os.system(\"csvformat -T temp_edge_list.csv > \"+name+\"_\"+str(e_val)+\"_edgelist.tsv\")\n",
    "    # Once converted to tsv, the temp csv edge list can be deleted\n",
    "    if os.path.exists(\"temp_edge_list.csv\"): os.remove(\"temp_edge_list.csv\")\n",
    "\n",
    "    print(\"5. Using ClusterONE to generate a list of clusters from the edge list\")\n",
    "    os.system('java -jar cluster_one-1.0.jar temp_edge_list.tsv -f \"edge_list\" -F \"csv\" > temp_clusterONE.csv')\n",
    "    \n",
    "    print(\"6. Starting processing of ClusterONE clusters\")\n",
    "    # Read input edge_list of 3 columns: node1, node2, weight. No header.\n",
    "    file_name = name+'_'+str(e_val)\n",
    "    edge_df = pd.read_csv('temp_edge_list.tsv', sep=\"\\t\", header=None)\n",
    "    # Read ClusterONE output results\n",
    "    dfone = pd.read_csv('temp_clusterONE.csv')\n",
    "    dfone = dfone[dfone[\"P-value\"]<0.1]\n",
    "    # Convert the node column of each cluster to a list of members\n",
    "    dfone[\"Members\"] = dfone[\"Members\"].apply(lambda x: x.split(\" \"))\n",
    "    if os.path.exists(\"temp_edge_list.tsv\"): os.remove(\"temp_edge_list.tsv\")\n",
    "    if os.path.exists(\"temp_clusterONE.csv\"): os.remove(\"temp_clusterONE.csv\")\n",
    "    \n",
    "    edges_in_clusters_df = parallel_is_in_cluster(edge_df, is_in_cluster)\n",
    "    edges_in_clusters_df[2] = edges_in_clusters_df[2].apply(lambda x: 1 - math.log(x) * e_val) # return original MR\n",
    "    edges_in_clusters_df.columns = [\"edge1\", \"edge2\", \"MR\"]\n",
    "    edges_in_clusters_df.to_csv(\"clusterONE/\"+file_name+\".tsv\", sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "    print(\"7. MR based coexpression network processing is complete \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-oasis",
   "metadata": {},
   "source": [
    "### Parallelize search for MR values for MR network edges\n",
    "This is not really necessary, but I like having the MR values in the final network edge file.\\\n",
    "I will try to add an option to skip this step to save on a couple of minutes of analysis for each network.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_cluster(splt):\n",
    "    # A function that keeps edges only if they are found within a ClusterONE cluster\n",
    "    return(splt[splt[[0,1]].apply(lambda a: \n",
    "        any(dfone[\"Members\"].apply(lambda x: set([a[0], a[1],]).issubset(x))), axis=1)])\n",
    "\n",
    "def parallel_is_in_cluster(df, func, n_cores=32):\n",
    "\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-qatar",
   "metadata": {},
   "source": [
    "# Step 1: Generate the all-vs-all MR correlation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of all the data files, such as gene expression data, \n",
    "# that will be used to generate the Mutual Rank correlation networks\n",
    "file_dict = {\n",
    "    \"name_1\": \"file_1.csv\",\n",
    "    \"name_2\": \"file_2.csv\",\n",
    "}\n",
    "\n",
    "for key, val in file_dict.items():\n",
    "    print(key)\n",
    "    if \".csv\" in val:\n",
    "        sep=\",\"\n",
    "    else:\n",
    "        sep=\"\\t\"\n",
    "    df = pd.read_csv(\"data/\"+val, index_col=0, sep=sep)\n",
    "    \n",
    "    # For the fvert index (C_123_full_name) keep only the compound ID\n",
    "    # ClusterONE doesn't work well with complex names\n",
    "    df.index = [\"C_\"+str(ix.split(\"_\")[1]) for ix in df.index.tolist()]\n",
    "    df = df.loc[~(df==0).all(axis=1)] # remove all-zero rows\n",
    "    #df = np.log2(df+1)\n",
    "    \n",
    "    # Generate the complete coexpression matrix\n",
    "    df = NaNCorrMp.calculate(df.T, n_jobs=32) \n",
    "    \n",
    "    # Calculate the Mutual Rank table by multiplying the correlation df ranks * t(df) ranks\n",
    "    df = np.sqrt(df.rank(ascending=False)) * np.sqrt(df.rank(axis=1, ascending=False))\n",
    "    \n",
    "    # Round and convert MR values to int8 to get better compression on results\n",
    "    df = df.round(decimals=0)\n",
    "    df[df>250] = 0\n",
    "    df = df - 125\n",
    "    df = df.astype(\"int8\") \n",
    "    dt.Frame(df).to_jay(\"mrs/\"+key+\".mrs.jay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-dollar",
   "metadata": {},
   "source": [
    "# Step 2: Run the ClusterONE analysis on the MR correlation table\n",
    "As described in the Wisecaver, 2017 paper. Use different e-values to increase the MR value threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, _ in file_dict.items():\n",
    "    e_vals = [5,10,15,20,25,30,35,40,45,50,60,70,80,90,100]\n",
    "    for e_val in e_vals:\n",
    "        mr_network(key, e_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

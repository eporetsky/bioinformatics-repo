{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datatable as dt\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import preprocessing\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "\n",
    "from nancorrmp.nancorrmp import NaNCorrMp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MR Network\n",
    "The code provided here is meant meant to facilitate Mutual Rank-based coexpression network analysis. \\\n",
    "For more information about Mutual Rank and how it can be used please check the Wisecaver manuscript and our Mutual Rank shiny app:\n",
    "* A Global Coexpression Network Approach for Connecting Genes to Specialized Metabolic Pathways in Plants (https://doi.org/10.1105/tpc.17.00009)\n",
    "* MutRank: an R shiny web-application for exploratory targeted mutual rank-based coexpression analyses integrated with user-provided supporting information (https://doi.org/10.7717/peerj.10264)\n",
    "* MutRank on Github: https://github.com/eporetsky/MutRank \\\n",
    "\n",
    "This code uses useful python packages to speed up the analysis, primarily: **nancorrmp** and **datatable**. \\\n",
    "It has not been thoroughly tested yet but I'll be happy to address any concerns by email: **eporetsky at ucsd.edu**. \\\n",
    "This code has been generated as part of my work in the **Huffaker lab** at University of California, San Diego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"input.csv\")\n",
    "df.iloc[:,2:] = np.log2(df.iloc[:,2:])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have columns to drop, this is the place. Only expression data from now on\n",
    "df = df.drop([\"id\",\"rep\"], axis=1)\n",
    "# Generate the complete coexpression matrix. Requires a lot of memory\n",
    "corr = NaNCorrMp.calculate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster save output. Produces a large file\n",
    "# name = \"analysis_name\"\n",
    "# dt.Frame(corr).to_csv(analysis_name+'_corr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Mutual Rank to ClusterONE network analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"analysis_name\"\n",
    "\n",
    "# Can skip step 1 if corr already in memory\n",
    "print(\"1. Starting analysis on correlation matrix named: \"+name)\n",
    "corr = dt.fread(name+'_corr.csv').to_pandas()\n",
    "corr.index = corr.columns\n",
    "\n",
    "print(\"2. Calculating the MR matrix\")\n",
    "# Generate the MR matrix from the corr\n",
    "corr = np.sqrt(corr.rank(ascending=False)) * np.sqrt(corr.rank(axis=1, ascending=False))\n",
    "\n",
    "# Convert the MR matrix to an exponential decay matrix\n",
    "e_val = 50\n",
    "print(\"3. Converting MR matrix using exponential decay (ED) value of: \"+str(e_val))\n",
    "corr = np.exp(-(corr-1.1)/e_val)\n",
    "corr = corr.mask(corr < 0.01, 0)\n",
    "corr = corr.loc[(corr.sum(axis=1) != 1), (corr.sum(axis=0) != 1)]\n",
    "\n",
    "print(\"4. Processing ED matrix in order produce an edge list file\")\n",
    "# Changes lower triangle and diagonal to NaN\n",
    "corr = corr.mask(np.arange(len(corr))[:,None] >= np.arange(len(corr)))\n",
    "# Make sure file doesn't exist because data appends to it\n",
    "if os.path.exists(\"temp_edge_list.csv\"): os.remove(\"temp_edge_list.csv\")\n",
    "\n",
    "# ClusterONE doesn't work with header\n",
    "range_indices = [[start, start+1000] for start in range(0, len(corr), 1000)]\n",
    "range_indices[-1][-1] = len(corr)\n",
    "for ind in range_indices:\n",
    "    a = corr.iloc[ind[0]:ind[1]].copy()\n",
    "    a = a.unstack().reset_index()\n",
    "    a = a[(a[0]>0) & ( ~ np.isnan(a[0]) )] # & (a[0]<1)]\n",
    "    dt.Frame(a).to_csv(\"temp_edge_list.csv\", append=True, header=False)\n",
    "# Since ClusterONE uses only tsv format for the edge list, and dt only saves csv need to convert\n",
    "os.system(\"csvformat -T temp_edge_list.csv > \"+name+\"_\"+str(e_val)+\"_edgelist.tsv\")\n",
    "# Once converted to tsv, the temp csv edge list can be deleted\n",
    "if os.path.exists(\"temp_edge_list.csv\"): os.remove(\"temp_edge_list.csv\")\n",
    "\n",
    "print(\"5. Using ClusterONE to generate a list of clusters from the edge list\")\n",
    "os.system('java -jar cluster_one-1.0.jar '+name+'_'+str(e_val)+'_edgelist.tsv -f \"edge_list\" -F \"csv\" > '+name+'_'+str(e_val)+'_clusterONE.csv')\n",
    "\n",
    "print(\"6. Starting processing of ClusterONE clusters\")\n",
    "dfone = pd.read_csv(name+'_'+str(e_val)+'_clusterONE.csv')\n",
    "dfone = dfone[dfone[\"P-value\"]<0.1]\n",
    "print(\"Number of clusters after p.value filtering:\", dfone.shape[0])\n",
    "output_df = pd.DataFrame(columns=[\"node1\", \"node2\", \"attribute\"])\n",
    "#adj = open('clusterone_adj_mre_met_'+str(c_val)+'_'+str(e_val)+'_cytoscape.csv', \"w\")\n",
    "for clusters in dfone[\"Members\"].to_list():\n",
    "    cluster = clusters.split(\" \")\n",
    "    combinations = list(itertools.combinations(cluster, 2))\n",
    "    for comb in combinations:\n",
    "        output_df.loc[len(output_df)] = [comb[0],comb[1],1]\n",
    "        #adj.write(comb[0]+\",\"+comb[1]+\",\"+\"1\"+\"\\n\")\n",
    "    # There could be overlap bertween the clusters and this helps  \n",
    "    output_df = output_df[~output_df[['node1', 'node2']].apply(frozenset, axis=1).duplicated()]\n",
    "\n",
    "print(\"Number of unique nodes in the final network: \" + str(len(set(output_df[\"node1\"]).union(set(output_df[\"node2\"])))))\n",
    "output_df.to_csv(name+'_'+str(e_val)+'_cytoscape.csv')\n",
    "print(\"7. MR based coexpression network processing is complete \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0430c45-ed7a-400b-a6ee-bc95b2164998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyopenms matchms networkx matplotlib pandas scipy seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e17c3-388e-4844-80dc-7356b060b5c0",
   "metadata": {},
   "source": [
    "# Load libraries and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760863e8-ce0b-4812-a46d-c1844c0934fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pyopenms import *\n",
    "from scipy.spatial.distance import cosine\n",
    "from matchms import Spectrum\n",
    "from matchms.similarity import ModifiedCosine\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to extract spectrum closest to a given retention time\n",
    "def extract_spectrum_at_rt(exp, target_rt, rt_window=0.5):\n",
    "    \"\"\"\n",
    "    Extracts the spectrum closest to the target retention time within a specified window.\n",
    "    \n",
    "    :param exp: MSExperiment object containing the spectra.\n",
    "    :param target_rt: Target retention time.\n",
    "    :param rt_window: Retention time window for selecting the spectrum.\n",
    "    :return: The spectrum closest to the target retention time.\n",
    "    \"\"\"\n",
    "    min_diff = float('inf')\n",
    "    selected_spectrum = None\n",
    "    for spectrum in exp:\n",
    "        rt = spectrum.getRT()\n",
    "        if abs(rt - target_rt) < rt_window and abs(rt - target_rt) < min_diff:\n",
    "            selected_spectrum = spectrum\n",
    "            min_diff = abs(rt - target_rt)\n",
    "    return selected_spectrum\n",
    "    \n",
    "# Compute similarity between spectra (using cosine similarity as an example)\n",
    "def compute_similarity(spectrum1, spectrum2):\n",
    "    mz1, intensity1 = spectrum1.get_peaks()\n",
    "    mz2, intensity2 = spectrum2.get_peaks()\n",
    "    intensity1 = (intensity1 / intensity1.sum())\n",
    "    intensity2 = (intensity2 / intensity2.sum())\n",
    "    mz1 = mz1.round()\n",
    "    mz2 = mz2.round()\n",
    "    intersect = set(mz1).intersection(mz2)\n",
    "    df1 = pd.DataFrame([mz1, intensity1]).T.drop_duplicates(0)\n",
    "    df2 = pd.DataFrame([mz2, intensity2]).T.drop_duplicates(0)\n",
    "    df1 = df1[df1[0].isin(intersect)]\n",
    "    df2 = df2[df2[0].isin(intersect)]\n",
    "    \n",
    "    # Simple cosine similarity - consider more sophisticated alignment and similarity for real applications\n",
    "    similarity = 1 - cosine(df1[1].tolist(), df2[1].tolist())\n",
    "    return similarity\n",
    "\n",
    "# Compute similarity between spectra (using cosine similarity as an example)\n",
    "# https://matchms.readthedocs.io/en/stable/api/matchms.similarity.html#matchms.similarity.ModifiedCosine\n",
    "def modified_cosine_similarity(spectrum1, spectrum2):\n",
    "    mz1, intensity1 = spectrum1.get_peaks()\n",
    "    mz2, intensity2 = spectrum2.get_peaks()\n",
    "    \n",
    "    intensity1 = (intensity1 / intensity1.sum()).astype(float)\n",
    "    intensity2 = (intensity2 / intensity2.sum()).astype(float)\n",
    "\n",
    "    spectrum_1 = Spectrum(mz=mz1.astype(float), intensities=intensity1, metadata={\"precursor_mz\": 1.0})\n",
    "    spectrum_2 = Spectrum(mz=mz2.astype(float), intensities=intensity2, metadata={\"precursor_mz\": 1.0})\n",
    "    \n",
    "    # Use factory to construct a similarity function\n",
    "    modified_cosine = ModifiedCosine(tolerance=2)\n",
    "    \n",
    "    score = modified_cosine.pair(spectrum_1, spectrum_2)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa769bde-78a9-4cb9-8f2a-cc760e9ac9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your metabolite retention times\n",
    "metabolites_df = pd.read_csv(\"Draft/metabolite_data.txt\", sep=\"\\t\")  # Assuming a CSV with 'Name' and 'RetentionTime' columns\n",
    "metabolites_df[\"rt\"] = metabolites_df[\"Name\"].str.split(\"_\").str[2].astype(float)\n",
    "metabolites_df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a885d-1506-4c71-bbd5-ab9b59b51a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dict = {'samle1': \"sample1.mzML\",\n",
    "'samle2': \"samle2.mzML\",\n",
    "'samle3': \"samle3.mzML\"}\n",
    "\n",
    "mog_cols = []\n",
    "for col in metabolites_df.columns:\n",
    "    if \"MoG\" in col:\n",
    "        mog_cols.append(col)\n",
    "tmp_df = metabolites_df[[\"Name\", \"rt\", \"Fold Change\", \"T-test\", \"class\"] + mog_cols]\n",
    "\n",
    "# Function to find the column name with the largest value\n",
    "def find_max_column(row):\n",
    "    # The `idxmax` method returns the index (column name in this case) of the first occurrence of maximum value\n",
    "    return row.idxmax()\n",
    "\n",
    "# Apply the function across the dataframe row-wise (axis=1)\n",
    "tmp_df['MaxValueColumn'] = tmp_df[mog_cols].apply(find_max_column, axis=1)\n",
    "tmp_df['filename'] = tmp_df['MaxValueColumn'].replace(sample_dict)\n",
    "tmp_df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03152196-f8dd-4b1f-87e1-755d6caf393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your raw file\n",
    "spectra_dict = {}\n",
    "\n",
    "for filename in tmp_df[\"filename\"].unique().tolist():\n",
    "    name_list = tmp_df[tmp_df[\"filename\"]==filename][\"Name\"].tolist()\n",
    "    rt_list = tmp_df[tmp_df[\"filename\"]==filename][\"rt\"].tolist()\n",
    "    file_path = \"mzML_converted/\" + filename\n",
    "    exp = MSExperiment()\n",
    "    MzMLFile().load(file_path, exp)\n",
    "\n",
    "    # Extract spectra for each metabolite\n",
    "    metabolite_spectra = {}\n",
    "    #for _, row in metabolites_df.iterrows():\n",
    "    for ix, rt in enumerate(rt_list):\n",
    "        #print(rt)\n",
    "        #break\n",
    "        spectrum = extract_spectrum_at_rt(exp, rt * 60)\n",
    "        spectra_dict[name_list[ix]] = spectrum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b4198f-6841-4c4b-b90a-db7b9b44c35f",
   "metadata": {},
   "source": [
    "# Regular Cosien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77fa478-222d-455a-a1dd-f05c932a4080",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Construct a similarity network\n",
    "G = nx.Graph()\n",
    "for name1, spectrum1 in spectra_dict.items():\n",
    "    for name2, spectrum2 in spectra_dict.items():\n",
    "        if name1 != name2:\n",
    "            similarity = compute_similarity(spectrum1, spectrum2)\n",
    "            if similarity > 0.5:  # Threshold for similarity to consider an edge\n",
    "                G.add_edge(name1, name2, weight=similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d98714-daeb-4d63-ab43-6e03be6f13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "F = G.copy()\n",
    "F.remove_edges_from([(n1, n2) for n1, n2, w in G.edges(data=\"weight\") if w < 0.75])\n",
    "\n",
    "# Visualize the network\n",
    "#pos = nx.spring_layout(F)\n",
    "pos = nx.kamada_kawai_layout(F)\n",
    "\n",
    "node_classes = tmp_df[[\"Name\", \"class\"]].set_index(\"Name\").to_dict()[\"class\"]\n",
    "# Assign class attributes to nodes in the graph\n",
    "nx.set_node_attributes(F, node_classes, 'class')\n",
    "\n",
    "\n",
    "# Unique classes and their corresponding indices\n",
    "unique_classes = tmp_df[\"class\"].unique().tolist()\n",
    "class_indices = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
    "\n",
    "# Use a Matplotlib colormap\n",
    "colormap = plt.cm.get_cmap('tab20', len(unique_classes))  # 'tab10' is a good choice for up to 10 classes\n",
    "\n",
    "# Generate colors for each node based on its class\n",
    "node_colors = [colormap(class_indices[F.nodes[node]['class']]) for node in F]\n",
    "\n",
    "# Draw the graph\n",
    "nx.draw(F, pos, with_labels=False, node_color=node_colors, node_size=100)\n",
    "\n",
    "# Create a legend\n",
    "legend_handles = [mpatches.Patch(color=colormap(i), label=cls) for cls, i in class_indices.items()]\n",
    "plt.legend(handles=legend_handles, title=\"Node Classes\", bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "#plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06fef0d-8e0a-4838-947c-0c2d8a61e23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "F = G.copy()\n",
    "F.remove_edges_from([(n1, n2) for n1, n2, w in G.edges(data=\"weight\") if w < 0.75])\n",
    "\n",
    "# Visualize the network\n",
    "#pos = nx.spring_layout(F)\n",
    "pos = nx.kamada_kawai_layout(F)\n",
    "\n",
    "node_classes = tmp_df[[\"Name\", \"class\"]].set_index(\"Name\").to_dict()[\"class\"]\n",
    "# Assign class attributes to nodes in the graph\n",
    "nx.set_node_attributes(F, node_classes, 'class')\n",
    "\n",
    "\n",
    "# Unique classes and their corresponding indices\n",
    "unique_classes = tmp_df[\"class\"].unique().tolist()\n",
    "class_indices = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
    "\n",
    "# Use a Matplotlib colormap\n",
    "colormap = plt.cm.get_cmap('tab20', len(unique_classes))  # 'tab10' is a good choice for up to 10 classes\n",
    "\n",
    "# Generate colors for each node based on its class\n",
    "node_colors = [colormap(class_indices[F.nodes[node]['class']]) for node in F]\n",
    "\n",
    "# Draw the graph\n",
    "nx.draw(F, pos, with_labels=False, node_color=node_colors, node_size=100)\n",
    "\n",
    "# Create a legend\n",
    "legend_handles = [mpatches.Patch(color=colormap(i), label=cls) for cls, i in class_indices.items()]\n",
    "plt.legend(handles=legend_handles, title=\"Node Classes\", bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "#plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff4d814-f1da-4f5a-b17e-afb649f23be8",
   "metadata": {},
   "source": [
    "# Modified Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d84ec-6eb3-47aa-8820-b916b7783dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a similarity network\n",
    "G_mod = nx.Graph()\n",
    "for name1, spectrum1 in spectra_dict.items():\n",
    "    for name2, spectrum2 in spectra_dict.items():\n",
    "        if name1 != name2:\n",
    "            similarity = modified_cosine_similarity(spectrum1, spectrum2)\n",
    "            if similarity['score'] > 0.5:  # Threshold for similarity to consider an edge\n",
    "                G_mod.add_edge(name1, name2, weight=float(similarity['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8290e4e-04c6-4ab6-8d5f-4033a758ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "F = G_mod.copy()\n",
    "F.remove_edges_from([(n1, n2) for n1, n2, w in F.edges(data=\"weight\") if w < 0.8])\n",
    "\n",
    "# Visualize the network\n",
    "#pos = nx.spring_layout(F)\n",
    "pos = nx.kamada_kawai_layout(F)\n",
    "\n",
    "node_classes = tmp_df[[\"Name\", \"class\"]].set_index(\"Name\").to_dict()[\"class\"]\n",
    "# Assign class attributes to nodes in the graph\n",
    "nx.set_node_attributes(F, node_classes, 'class')\n",
    "\n",
    "\n",
    "# Unique classes and their corresponding indices\n",
    "unique_classes = tmp_df[\"class\"].unique().tolist()\n",
    "class_indices = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
    "\n",
    "# Use a Matplotlib colormap\n",
    "colormap = plt.cm.get_cmap('tab20', len(unique_classes))  # 'tab10' is a good choice for up to 10 classes\n",
    "\n",
    "# Generate colors for each node based on its class\n",
    "node_colors = [colormap(class_indices[F.nodes[node]['class']]) for node in F]\n",
    "\n",
    "# Draw the graph\n",
    "nx.draw(F, pos, with_labels=False, node_color=node_colors, node_size=100)\n",
    "\n",
    "# Create a legend\n",
    "legend_handles = [mpatches.Patch(color=colormap(i), label=cls) for cls, i in class_indices.items()]\n",
    "plt.legend(handles=legend_handles, title=\"Node Classes\", bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "#plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efbcbaf-ed44-4382-9fb0-0a90b2f1e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the graph as an edge list\n",
    "# Assuming G is your NetworkX graph\n",
    "edges = nx.to_pandas_edgelist(F)\n",
    "edges.to_csv('edges.tsv', index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

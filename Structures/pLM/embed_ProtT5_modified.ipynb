{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QMoeBQnUCK_E"
   },
   "outputs": [],
   "source": [
    "#@title Install requirements. { display-mode: \"form\" }\n",
    "# Install requirements\n",
    "#!pip install torch transformers sentencepiece h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "id": "tRe7CfuqFFmY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file protT5 already exists.\n",
      "Error occurred while processing: protT5.\n",
      "A subdirectory or file # already exists.\n",
      "Error occurred while processing: #.\n",
      "A subdirectory or file root already exists.\n",
      "Error occurred while processing: root.\n",
      "A subdirectory or file directory already exists.\n",
      "Error occurred while processing: directory.\n",
      "A subdirectory or file for already exists.\n",
      "Error occurred while processing: for.\n",
      "A subdirectory or file storing already exists.\n",
      "Error occurred while processing: storing.\n",
      "A subdirectory or file checkpoints already exists.\n",
      "Error occurred while processing: checkpoints.\n",
      "A subdirectory or file results already exists.\n",
      "Error occurred while processing: results.\n",
      "A subdirectory or file etc already exists.\n",
      "Error occurred while processing: etc.\n",
      "The syntax of the command is incorrect.\n",
      "The syntax of the command is incorrect.\n",
      "The syntax of the command is incorrect.\n",
      "'predictions' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#@title Set up working directories and download files/checkpoints. { display-mode: \"form\" }\n",
    "# Create directory for storing model weights (2.3GB) and example sequences.\n",
    "# Here we use the encoder-part of ProtT5-XL-U50 in half-precision (fp16) as \n",
    "# it performed best in our benchmarks (also outperforming ProtBERT-BFD).\n",
    "# Also download secondary structure prediction checkpoint to show annotation extraction from embeddings\n",
    "!mkdir protT5 # root directory for storing checkpoints, results etc\n",
    "!mkdir protT5/protT5_checkpoint # directory holding the ProtT5 checkpoint\n",
    "!mkdir protT5/sec_struct_checkpoint # directory storing the supervised classifier's checkpoint\n",
    "!mkdir protT5/output # directory for storing your embeddings & predictions\n",
    "!wget -nc -P protT5/ https://rostlab.org/~deepppi/example_seqs.fasta\n",
    "# Huge kudos to the bio_embeddings team here! We will integrate the new encoder, half-prec ProtT5 checkpoint soon\n",
    "!wget -nc -P protT5/sec_struct_checkpoint http://data.bioembeddings.com/public/embeddings/feature_models/t5/secstruct_checkpoint.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZQotVM94S7NR"
   },
   "outputs": [],
   "source": [
    "# In the following you can define your desired output. Current options:\n",
    "# per_residue embeddings\n",
    "# per_protein embeddings\n",
    "# secondary structure predictions\n",
    "\n",
    "# Replace this file with your own (multi-)FASTA\n",
    "# Headers are expected to start with \">\";\n",
    "#seq_path = \"protT5/Zmays_493_RefGen_V4.protein_primaryTranscriptOnly.canonical.fa\"\n",
    "\n",
    "seq_name = \"fasta_file_name\"\n",
    "seq_path = \"protT5/\"+seq_name+\".fa\"\n",
    "\n",
    "# whether to retrieve embeddings for each residue in a protein \n",
    "# --> Lx1024 matrix per protein with L being the protein's length\n",
    "# as a rule of thumb: 1k proteins require around 1GB RAM/disk\n",
    "per_residue = True \n",
    "per_residue_path = \"protT5/output/\"+seq_name+\".residue.h5\" # where to store the embeddings\n",
    "\n",
    "# whether to retrieve per-protein embeddings \n",
    "# --> only one 1024-d vector per protein, irrespective of its length\n",
    "per_protein = True\n",
    "per_protein_path = \"protT5/output/\"+seq_name+\".protein.h5\" # where to store the embeddings\n",
    "\n",
    "# whether to retrieve secondary structure predictions\n",
    "# This can be replaced by your method after being trained on ProtT5 embeddings\n",
    "sec_struct = True\n",
    "sec_struct_path = \"protT5/output/\"+seq_name+\".struct.fa\" # file for storing predictions\n",
    "\n",
    "# make sure that either per-residue or per-protein embeddings are stored\n",
    "assert per_protein is True or per_residue is True or sec_struct is True, print(\n",
    "    \"Minimally, you need to active per_residue, per_protein or sec_struct. (or any combination)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ET2v51slC5ui",
    "outputId": "15fa3a38-55dc-4e06-c1e2-5e6783df8456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    }
   ],
   "source": [
    "#@title Import dependencies and check whether GPU is available. { display-mode: \"form\" }\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "import torch\n",
    "import h5py\n",
    "import time\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device(\"cpu\")\n",
    "print(\"Using {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "c5XqIyeNStZP"
   },
   "outputs": [],
   "source": [
    "#@title Network architecture for secondary structure prediction. { display-mode: \"form\" }\n",
    "# Convolutional neural network (two convolutional layers) to predict secondary structure\n",
    "class ConvNet( torch.nn.Module ):\n",
    "    def __init__( self ):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # This is only called \"elmo_feature_extractor\" for historic reason\n",
    "        # CNN weights are trained on ProtT5 embeddings\n",
    "        self.elmo_feature_extractor = torch.nn.Sequential(\n",
    "                        torch.nn.Conv2d( 1024, 32, kernel_size=(7,1), padding=(3,0) ), # 7x32\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Dropout( 0.25 ),\n",
    "                        )\n",
    "        n_final_in = 32\n",
    "        self.dssp3_classifier = torch.nn.Sequential(\n",
    "                        torch.nn.Conv2d( n_final_in, 3, kernel_size=(7,1), padding=(3,0)) # 7\n",
    "                        )\n",
    "        \n",
    "        self.dssp8_classifier = torch.nn.Sequential(\n",
    "                        torch.nn.Conv2d( n_final_in, 8, kernel_size=(7,1), padding=(3,0))\n",
    "                        )\n",
    "        self.diso_classifier = torch.nn.Sequential(\n",
    "                        torch.nn.Conv2d( n_final_in, 2, kernel_size=(7,1), padding=(3,0))\n",
    "                        )\n",
    "        \n",
    "\n",
    "    def forward( self, x):\n",
    "        # IN: X = (B x L x F); OUT: (B x F x L, 1)\n",
    "        x = x.permute(0,2,1).unsqueeze(dim=-1) \n",
    "        x         = self.elmo_feature_extractor(x) # OUT: (B x 32 x L x 1)\n",
    "        d3_Yhat   = self.dssp3_classifier( x ).squeeze(dim=-1).permute(0,2,1) # OUT: (B x L x 3)\n",
    "        d8_Yhat   = self.dssp8_classifier( x ).squeeze(dim=-1).permute(0,2,1) # OUT: (B x L x 8)\n",
    "        diso_Yhat = self.diso_classifier(  x ).squeeze(dim=-1).permute(0,2,1) # OUT: (B x L x 2)\n",
    "        return d3_Yhat, d8_Yhat, diso_Yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YLYFPAT_VLAK"
   },
   "outputs": [],
   "source": [
    "#@title Load the checkpoint for secondary structure prediction. { display-mode: \"form\" }\n",
    "def load_sec_struct_model():\n",
    "  checkpoint_dir=\"./protT5/sec_struct_checkpoint/secstruct_checkpoint.pt\"\n",
    "  state = torch.load( checkpoint_dir )\n",
    "  model = ConvNet()\n",
    "  model.load_state_dict(state['state_dict'])\n",
    "  model = model.eval()\n",
    "\n",
    "  # https://github.com/agemagician/ProtTrans/blob/cc432db8ce0b28754a4383f53b0a387267574f1c/Embedding/PyTorch/Use_Case:NetSurfp_Dataset_Secondary_Structure_Prediction_(3_States)_Feature_Extraction.ipynb\n",
    "  if torch.cuda.is_available():\n",
    "    model = model.half()\n",
    "\n",
    "  model = model.to(device)\n",
    "  # I'm not sure if this information about the epoch is important\n",
    "  #print('Loaded sec. struct. model from epoch: {:.1f}'.format(state['epoch']))\n",
    "\n",
    "  \n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tLDz6jv1C0UI"
   },
   "outputs": [],
   "source": [
    "#@title Load encoder-part of ProtT5 in half-precision. { display-mode: \"form\" }\n",
    "# Load ProtT5 in half-precision (more specifically: the encoder-part of ProtT5-XL-U50) \n",
    "def get_T5_model():\n",
    "    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\")\n",
    "    model = model.to(device) # move model to GPU\n",
    "    model = model.eval() # set model to evaluation model\n",
    "    \n",
    "    # https://github.com/agemagician/ProtTrans/blob/cc432db8ce0b28754a4383f53b0a387267574f1c/Embedding/PyTorch/Use_Case:NetSurfp_Dataset_Secondary_Structure_Prediction_(3_States)_Feature_Extraction.ipynb\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.half()\n",
    "    \n",
    "    tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6OC1toF1EM9n"
   },
   "outputs": [],
   "source": [
    "#@title Read in file in fasta format. { display-mode: \"form\" }\n",
    "def read_fasta( fasta_path, split_char=\"!\", id_field=0):\n",
    "    '''\n",
    "        Reads in fasta file containing multiple sequences.\n",
    "        Split_char and id_field allow to control identifier extraction from header.\n",
    "        E.g.: set split_char=\"|\" and id_field=1 for SwissProt/UniProt Headers.\n",
    "        Returns dictionary holding multiple sequences or only single \n",
    "        sequence, depending on input file.\n",
    "    '''\n",
    "    \n",
    "    seqs = dict()\n",
    "    with open( fasta_path, 'r' ) as fasta_f:\n",
    "        for line in fasta_f:\n",
    "            # get uniprot ID from header and create new entry\n",
    "            if line.startswith('>'):\n",
    "                uniprot_id = line.replace('>', '').strip().split(split_char)[id_field]\n",
    "                # replace tokens that are mis-interpreted when loading h5\n",
    "                uniprot_id = uniprot_id.replace(\"/\",\"_\").replace(\".\",\"_\")\n",
    "                seqs[ uniprot_id ] = ''\n",
    "            else:\n",
    "                # repl. all whie-space chars and join seqs spanning multiple lines, drop gaps and cast to upper-case\n",
    "                seq= ''.join( line.split() ).upper().replace(\"-\",\"\")\n",
    "                # repl. all non-standard AAs and map them to unknown/X\n",
    "                seq = seq.replace('U','X').replace('Z','X').replace('O','X')\n",
    "                seqs[ uniprot_id ] += seq \n",
    "    example_id=next(iter(seqs))\n",
    "    print(\"Read {} sequences.\".format(len(seqs)))\n",
    "    print(\"Example:\\n{}\\n{}\".format(example_id,seqs[example_id]))\n",
    "\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nK4hwGggR_Rs"
   },
   "outputs": [],
   "source": [
    "#@title Generate embeddings. { display-mode: \"form\" }\n",
    "# Generate embeddings via batch-processing\n",
    "# per_residue indicates that embeddings for each residue in a protein should be returned.\n",
    "# per_protein indicates that embeddings for a whole protein should be returned (average-pooling)\n",
    "# max_residues gives the upper limit of residues within one batch\n",
    "# max_seq_len gives the upper sequences length for applying batch-processing\n",
    "# max_batch gives the upper number of sequences per batch\n",
    "def get_embeddings( model, tokenizer, seqs, per_residue, per_protein, sec_struct, \n",
    "                   max_residues=4000, max_seq_len=1000, max_batch=100 ):\n",
    "\n",
    "    if sec_struct:\n",
    "      sec_struct_model = load_sec_struct_model()\n",
    "\n",
    "    results = {\"residue_embs\" : dict(), \n",
    "               \"protein_embs\" : dict(),\n",
    "               \"sec_structs\" : dict() \n",
    "               }\n",
    "\n",
    "    # sort sequences according to length (reduces unnecessary padding --> speeds up embedding)\n",
    "    seq_dict   = sorted( seqs.items(), key=lambda kv: len( seqs[kv[0]] ), reverse=True )\n",
    "    start = time.time()\n",
    "    batch = list()\n",
    "    \n",
    "    for seq_idx, (pdb_id, seq) in enumerate(seq_dict,1):\n",
    "                \n",
    "        seq = seq\n",
    "        seq_len = len(seq)\n",
    "        seq = ' '.join(list(seq))\n",
    "        batch.append((pdb_id,seq,seq_len))\n",
    "\n",
    "        # count residues in current batch and add the last sequence length to\n",
    "        # avoid that batches with (n_res_batch > max_residues) get processed \n",
    "        n_res_batch = sum([ s_len for  _, _, s_len in batch ]) + seq_len \n",
    "        if len(batch) >= max_batch or n_res_batch>=max_residues or seq_idx==len(seq_dict) or seq_len>max_seq_len:\n",
    "            pdb_ids, seqs, seq_lens = zip(*batch)\n",
    "            batch = list()\n",
    "\n",
    "            # add_special_tokens adds extra token at the end of each sequence\n",
    "            token_encoding = tokenizer.batch_encode_plus(seqs, add_special_tokens=True, padding=\"longest\")\n",
    "            input_ids      = torch.tensor(token_encoding['input_ids']).to(device)\n",
    "            attention_mask = torch.tensor(token_encoding['attention_mask']).to(device)\n",
    "            \n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    # returns: ( batch-size x max_seq_len_in_minibatch x embedding_dim )\n",
    "                    embedding_repr = model(input_ids, attention_mask=attention_mask)\n",
    "            except RuntimeError:\n",
    "                print(\"RuntimeError during embedding for {} (L={})\".format(pdb_id, seq_len))\n",
    "                continue\n",
    "\n",
    "            if sec_struct: # in case you want to predict secondary structure from embeddings\n",
    "              d3_Yhat, d8_Yhat, diso_Yhat = sec_struct_model(embedding_repr.last_hidden_state)\n",
    "\n",
    "\n",
    "            for batch_idx, identifier in enumerate(pdb_ids): # for each protein in the current mini-batch\n",
    "                s_len = seq_lens[batch_idx]\n",
    "                # slice off padding --> batch-size x seq_len x embedding_dim  \n",
    "                emb = embedding_repr.last_hidden_state[batch_idx,:s_len]\n",
    "                if sec_struct: # get classification results\n",
    "                    results[\"sec_structs\"][identifier] = torch.max( d3_Yhat[batch_idx,:s_len], dim=1 )[1].detach().cpu().numpy().squeeze()\n",
    "                if per_residue: # store per-residue embeddings (Lx1024)\n",
    "                    results[\"residue_embs\"][ identifier ] = emb.detach().cpu().numpy().squeeze()\n",
    "                if per_protein: # apply average-pooling to derive per-protein embeddings (1024-d)\n",
    "                    protein_emb = emb.mean(dim=0)\n",
    "                    results[\"protein_embs\"][identifier] = protein_emb.detach().cpu().numpy().squeeze()\n",
    "\n",
    "\n",
    "    passed_time=time.time()-start\n",
    "    avg_time = passed_time/len(results[\"residue_embs\"]) if per_residue else passed_time/len(results[\"protein_embs\"])\n",
    "    print('\\n############# EMBEDDING STATS #############')\n",
    "    print('Total number of per-residue embeddings: {}'.format(len(results[\"residue_embs\"])))\n",
    "    print('Total number of per-protein embeddings: {}'.format(len(results[\"protein_embs\"])))\n",
    "    print(\"Time for generating embeddings: {:.1f}[m] ({:.3f}[s/protein])\".format(\n",
    "        passed_time/60, avg_time ))\n",
    "    print('\\n############# END #############')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UB6yhwunTymY"
   },
   "outputs": [],
   "source": [
    "#@title Write embeddings to disk. { display-mode: \"form\" }\n",
    "# I replace the \"w\" with \"a\" so I can append embeddings with a for-loop\n",
    "def save_embeddings(emb_dict,out_path):\n",
    "    with h5py.File(str(out_path), \"a\") as hf:\n",
    "        for sequence_id, embedding in emb_dict.items():\n",
    "            # noinspection PyUnboundLocalVariable\n",
    "            hf.create_dataset(sequence_id, data=embedding)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "juXcP5Tpbeqv"
   },
   "outputs": [],
   "source": [
    "#@title Write predictions to disk. { display-mode: \"form\" }\n",
    "def write_prediction_fasta(predictions, out_path):\n",
    "  class_mapping = {0:\"H\",1:\"E\",2:\"L\"} \n",
    "  with open(out_path, 'w+') as out_f:\n",
    "      out_f.write( '\\n'.join( \n",
    "          [ \">{}\\n{}\".format( \n",
    "              seq_id, ''.join( [class_mapping[j] for j in yhat] )) \n",
    "          for seq_id, yhat in predictions.items()\n",
    "          ] \n",
    "            ) )\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 39498 sequences.\n",
      "Example:\n",
      "Zm00001d000434\n",
      "MALSIIPSTSSGEHAAASASATATTTTKLGQLNAAVERSWVGRRFRLAARGTTFTTELRAGTATFLTMAYILAVNASILSDSGATCTVDDCDVPSPGCKFPPVDPGYAACVARVRRDLIVATAASSVIGSFIMGAFANLPIALAPGMGTNAYFAYTVVGFHGSGTLPYRTALAAVFLEGLIFLFISIVGLRSKLAQFIPTPVRISASAGIGLFLAFIGLQSNEGVGLVGFSSSTLVTLGACPASQRASVAPVLTFPNGTVALMPGGTVSGGILCLSGRMTSPTFWLAVVGFLIIAFCLIKRVKGALIYGILFVTFVSWPRHTAVTAFPDTPAGDDSFHYFKKVFDVHRIRSTAGALDFSGIGQGYFWEALFTFLYVDILDTTGSLYTMARFAGFVDDATGEFEGQYFAFMSDATAIVFGSLLGTSPVTAFIESSTGIREGGRTGLTALTAAIYFAAALFITPVLASIPSWAVGPPLVLVGVMMMRAVAEVDWDDMRQAVPAFLTLALMPLTYSIAYGLIGGIASYMLLHSWDWACQATRRLGCLKKGGGGADSTNGGVAEQSVEEQRKDMESA\n"
     ]
    }
   ],
   "source": [
    "# Load fasta.\n",
    "seqs = read_fasta(seq_path)\n",
    "\n",
    "# Load the encoder part of ProtT5-XL-U50 in half-precision (recommended)\n",
    "model, tokenizer = get_T5_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 1 out of 20\n",
      "RuntimeError during embedding for Zm00001d022338 (L=3882)\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/22878743/how-to-split-dictionary-into-multiple-dictionaries-fast\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "def chunks(data, SIZE):\n",
    "    it = iter(data)\n",
    "    for i in range(0, len(data), SIZE):\n",
    "        yield {k:data[k] for k in islice(it, SIZE)}\n",
    "\n",
    "protein_embeddings = {}\n",
    "structure_predicts = {}\n",
    "\n",
    "\n",
    "slice_size = 2000\n",
    "count = 0\n",
    "for seqs_slice in chunks(seqs, slice_size):\n",
    "  # Load the encoder part of ProtT5-XL-U50 in half-precision (recommended)\n",
    "  count += 1\n",
    "  print(\"Processing:\", count, \"out of\", str((len(seqs) // slice_size) + 1))\n",
    "\n",
    "  # Compute embeddings and/or secondary structure predictions\n",
    "  results = get_embeddings(model, tokenizer, seqs_slice,\n",
    "                          per_residue, per_protein, sec_struct)\n",
    "  \n",
    "  # merge protein embedding dictionaries\n",
    "  protein_embeddings = {**protein_embeddings, **results[\"protein_embs\"]}\n",
    "  \n",
    "  # merge structure prediction fasta dictionaries\n",
    "  structure_predicts = {**structure_predicts, **results[\"sec_structs\"]}\n",
    "\n",
    "  # save residue embeddings\n",
    "  per_residue_path = per_residue_path = \"protT5/output/\"+seq_name+\".residue.h5\" # where to store the embeddings\n",
    "\n",
    "  # Store per-residue embeddings\n",
    "  if per_residue:\n",
    "    save_embeddings(results[\"residue_embs\"], per_residue_path)\n",
    "    #files.download(per_residue_path) \n",
    "\n",
    "if per_protein:\n",
    "  save_embeddings(protein_embeddings, per_protein_path)\n",
    "  #files.download(per_protein_path) \n",
    "\n",
    "if sec_struct:\n",
    "  write_prediction_fasta(structure_predicts, sec_struct_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "history_visible": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

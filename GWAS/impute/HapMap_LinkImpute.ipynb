{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e692ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datatable as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf25fb6",
   "metadata": {},
   "source": [
    "# LinkImpute\n",
    "Download from: http://www.cultivatingdiversity.org/software.html\n",
    "\n",
    "Citation: https://www.g3journal.org/content/5/11/2383\n",
    "\n",
    "To run: java -jar LinkImpute.jar -a numeric.array imputed.array\n",
    "\n",
    "TODO: Add a small sample hapmap file for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7989da",
   "metadata": {},
   "source": [
    "# Convert hapmap file to LinkImpute numeric array and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c469b56a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the hapmap file and remove the unused columns\n",
    "\n",
    "# Couldn't finish anaylsis of raw data (~2M SNPs) withon 8 hours. Using filtered instead (~200k SNPs)\n",
    "df = pd.read_csv(\"name.hmp.txt\", sep=\"\\t\")\n",
    "df = df.drop(df.columns[4:11], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc70e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only allele pairs of interest\n",
    "df = df[df[\"alleles\"].isin([\"A/T\", \"A/G\", \"A/C\",\n",
    "                            \"T/A\", \"T/G\", \"T/C\",\n",
    "                            \"G/C\", \"G/T\", \"G/A\",\n",
    "                            \"C/A\", \"C/G\", \"C/T\"])]\n",
    "# To see if any allele did not pass use: \"C/A\", \"C/G\", \"C/T\"]) == False] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numeric(row):\n",
    "    # Sometimes returns key errors. Replace them with N\n",
    "    # It is much slower so commented-out by default\n",
    "    # for IUPAC in ['Y','R','W','S','K','M','D','V','H','B']: \n",
    "    #    row = row.str.replace(IUPAC, \"N\")    \n",
    "    \n",
    "    row_list = row.tolist()\n",
    "    # Convert the left allele to 0, right to 1, and missing to -1\n",
    "    allele_dict = {row_list[1][0]: 0, row_list[1][-1]: 1, \"N\": -1}\n",
    "    row_list[4:] = [allele_dict[allele] for allele in row_list[4:]]\n",
    "    return pd.Series(row_list)\n",
    "\n",
    "# Apply function to all rows\n",
    "df = df.apply(to_numeric, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db17e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data for the array format that can be used directly with the LinkImpute package\n",
    "array_format = df.T\n",
    "array_format = array_format.drop(array_format.index[:4])\n",
    "array_format.to_csv(\"numeric.array\", sep=\" \", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49740739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the LinkUmpute output and put it back together with the original hapmap file \n",
    "imp = pd.read_csv(\"imputed.array\", sep=\"\\t\", header=None).T\n",
    "df = pd.read_csv(\"name.hmp.txt\", sep=\"\\t\")\n",
    "df = df[df[\"alleles\"].isin([\"A/T\", \"A/G\", \"A/C\",\n",
    "                            \"T/A\", \"T/G\", \"T/C\",\n",
    "                            \"G/C\", \"G/T\", \"G/A\",\n",
    "                            \"C/A\", \"C/G\", \"C/T\"])]\n",
    "df = df.reset_index(drop=True)\n",
    "df.iloc[:,11:] = imp\n",
    "columns = df.columns # not sure why column names are deleted later\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4b44cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After imputation reverse the numeric format to allelic to load hapmap file in TASSEL\n",
    "def to_allelic(row):\n",
    "    row_list = row.tolist()\n",
    "    # Convert the left allele to 0, right to 1, and missing to -1\n",
    "    allele_dict = {0: row_list[1][0], 1: row_list[1][-1], -1:\"N\"}\n",
    "    row_list[11:] = [allele_dict[allele] for allele in row_list[11:]]\n",
    "    return pd.Series(row_list)\n",
    "\n",
    "hmp = df.apply(to_allelic, axis=1)\n",
    "hmp.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmp.to_csv(\"name.linkImpute.hmp.txt\", sep=\"\\t\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

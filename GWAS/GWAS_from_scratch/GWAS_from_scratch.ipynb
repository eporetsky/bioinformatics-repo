{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmp = pd.read_csv(\"test_hapmap.txt\", sep=\"\\t\", index_col=0)\n",
    "hmp = hmp.iloc[:,10:] # HapMap files come with 10 unused columns\n",
    "hmp = hmp.replace(\"N\", np.nan)\n",
    "\n",
    "trait = pd.read_csv(\"test_trait.txt\", sep=\"\\t\", index_col=0)\n",
    "trait.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. OLS GWAS\n",
    "\n",
    "Currently only implemented for a single SNP but the result match TASSEL GLM output for the tested SNP.\\\n",
    "Thia is also likely to be too slow to calculate the test statistics for thousands of SNPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge genotype column and trait column in a single dataframe\n",
    "data = pd.DataFrame(hmp.loc[\"SNP_Name\"]).join(trait[\"Trait_Name\"])\n",
    "data.columns = [\"SNP\", \"trait\"]\n",
    "data = pd.DataFrame(data)\n",
    "data[\"SNP\"] = data[\"SNP\"].replace(\"N\", np.nan)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinalenc = OrdinalEncoder()\n",
    "data.SNP = ordinalenc.fit_transform(pd.DataFrame(data.SNP))\n",
    "data = data.dropna()\n",
    "data.SNP = sm.add_constant(data.SNP)\n",
    "model = sm.OLS(data.trait, data.SNP).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculate Distance Matrix\n",
    "\n",
    "https://bitbucket.org/tasseladmin/tassel-5-source/wiki/UserManual/DistanceMatrix/DistanceMatrix \\\n",
    "https://davetang.org/muse/2015/07/24/dna-sequencing-data/ \\\n",
    "TASSEL calculates distance as 1 - IBS (identity by state) similarity, with IBS defined as the probability that alleles drawn at random from two individuals at the same locus are the same. For clustering, the distance of an individual from itself is set to 0.\n",
    "\n",
    "The calculation is based on the definition. For a bi-allelic locus with alleles A and B, probabilityIBS(AA,AA) = 1, pIBS(AA,BB) = 0, pIBS(AB, xx) = 0.5, where xx is any other genotype. For two taxa, pIBS is averaged over all non-missing loci. Distance is 1 - pIBS. The kinship calculation is related but different and is described in Endelman and Jannink (2012) Shrinkage Estimation of the Realized Relationship Matrix. G3 2:1405-1413, using the non-shrunk version under the assumption that generally, number of markers > number of individuals.\n",
    "\n",
    "Below is a python implementation of the IBM calculation using numpy vectorization. It assumes the hapmap file has only mono-allelic sites and only works for standard homozygous (\"G\", \"C\", \"A\", \"T\") and missing (\"N\") alleles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-vectorize-pairwise-dis-similarity-metrics-5d522715fb4e\n",
    "hmp = pd.read_csv(\"test_hapmap.txt\", sep=\"\\t\", index_col=0)\n",
    "hmp = hmp.iloc[:,10:]\n",
    "\n",
    "# First step is to calculate all non-missing loci in a 2-d numpy array\n",
    "X = hmp.copy()\n",
    "X = X.replace([\"G\",\"C\",\"A\",\"T\"],True)\n",
    "X = X.replace(\"N\",False)\n",
    "X = np.array(X.T)\n",
    "count_loc = np.empty((len(X), len(X)))\n",
    "count_loc = (X[:, None, :]) & (X[None, :, :])\n",
    "count_loc = count_loc.sum(axis=-1)\n",
    "\n",
    "# Second step is to calculate all matching loci (np.nan==np.nan is false) in a 2-d numpy array\n",
    "X = hmp.copy()\n",
    "X = X.replace(\"N\", np.nan)\n",
    "X = np.array(X.T)\n",
    "count_match = np.empty((len(X), len(X)))\n",
    "count_match = X[:, None, :] == X[None, :, :]\n",
    "count_match = count_match.sum(axis=-1)\n",
    "\n",
    "# Third step is to calculate the 1 - IBS (IBS=matching/non-missing loci)\n",
    "IBS = pd.DataFrame(1-(count_match/count_loc))\n",
    "IBS.index = hmp.columns\n",
    "IBS.columns = hmp.columns\n",
    "IBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This solution to calculate non-missing loci technically works but the\n",
    "# addition of the two vectorized numpy arrays is very non-memory efficient\n",
    "# (required about 80gb of RAM with just 13k SNPs in the hapmap file)\n",
    "# custom function to count non-missing loci\n",
    "def N_in(x):\n",
    "    return len(x) - sum('N' in s for s in x)\n",
    "\n",
    "X = np.array(X.T)\n",
    "count_loc = np.empty((len(X), len(X)))\n",
    "count_loc = X[:, None, :] + X[None, :, :]\n",
    "count_loc = np.apply_along_axis(N_in, -1, count_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This solution works but to calculate 1-IBS works but is slow due to nested loops\n",
    "hmp = pd.read_csv(\"test_hapmap.txt\", sep=\"\\t\", index_col=0)\n",
    "hmp = hmp.iloc[:,10:]\n",
    "hmp = hmp.replace(\"N\", np.nan)\n",
    "IBS  = pd.DataFrame(columns = hmp.columns, index=hmp.columns)\n",
    "for ix1, row1 in hmp.T.iterrows():\n",
    "    for ix2, row2 in hmp.T.iterrows():\n",
    "        count_loc = (row1+row2).count()\n",
    "        count_match = (row1==row2).sum()\n",
    "        IBS.loc[ix1,ix2] = 1-count_match/count_loc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
